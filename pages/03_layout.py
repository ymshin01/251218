import streamlit as st
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import os

# 1. íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ë°ì´í„° ë§ˆë²•ì‚¬", page_icon="ðŸª„", layout="wide")

# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_weather():
    try:
        df = pd.read_csv("test.csv")
        # ë‚ ì§œ ë°ì´í„° ì „ì²˜ë¦¬ (ê³µë°± ì œê±° ë° ë³€í™˜)
        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'].str.strip())
        return df
    except Exception as e:
        return None

@st.cache_data
def load_mbti():
    try:
        return pd.read_csv("countries.csv")
    except Exception as e:
        return None

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì˜¤ë¥˜ ì²˜ë¦¬
weather_df = load_weather()
mbti_df = load_mbti()

if weather_df is None or mbti_df is None:
    st.error("ðŸš¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— 'test.csv'ì™€ 'countries.csv'ê°€ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 2. ì‚¬ì´ë“œë°” (ì„¤ì • ì˜ì—­) ---
with st.sidebar:
    st.title("ðŸŽ¨ ì•± ì„¤ì •")
    # [ìˆ˜ì • 1] .strip()ì€ ë‚˜ì¤‘ì— ì ìš©í•˜ë”ë¼ë„, ìž…ë ¥ì°½ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
    api_key_input = st.text_input("ðŸ”‘ Gemini API Keyë¥¼ ìž…ë ¥í•˜ì„¸ìš”", type="password")
    
    # [ìˆ˜ì • 1 í•µì‹¬] ê³µë°± ì œê±° ì²˜ë¦¬
    user_api_key = api_key_input.strip() if api_key_input else ""
    
    st.divider()
    
    # êµ­ê°€ ì„ íƒ
    all_countries = mbti_df['Country'].unique()
    target_country = st.selectbox("ðŸŒ ë¶„ì„í•  êµ­ê°€", all_countries, 
                                  index=list(all_countries).index("South Korea") if "South Korea" in all_countries else 0)

    # ì—°ë„ ë²”ìœ„ ì„ íƒ
    min_year = int(weather_df['ë‚ ì§œ'].dt.year.min())
    max_year = int(weather_df['ë‚ ì§œ'].dt.year.max())
    year_range = st.slider("ðŸ“… ê¸°ì˜¨ ë¶„ì„ ê¸°ê°„", min_year, max_year, (2020, 2024))

# --- 3. ë©”ì¸ í™”ë©´ ---
st.title("âœ¨ AI ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ")

tab1, tab2 = st.tabs(["ðŸŒ¡ï¸ ê¸°í›„ ë³€í™” ë¶„ì„", "ðŸ§  êµ­ê°€ë³„ MBTI í†µê³„"])

# --- [Tab 1: ê¸°í›„ ë³€í™” ë¶„ì„] ---
with tab1:
    st.header("ì„œìš¸ì˜ ì˜¨ë„ ë³€í™” ë¶„ì„")
    
    filtered_weather = weather_df[(weather_df['ë‚ ì§œ'].dt.year >= year_range[0]) & 
                                  (weather_df['ë‚ ì§œ'].dt.year <= year_range[1])]
    
    col1, col2 = st.columns([7, 3])
    
    with col1:
        fig_line = px.line(filtered_weather, x='ë‚ ì§œ', y='í‰ê· ê¸°ì˜¨(â„ƒ)', 
                           title=f"{year_range[0]}ë…„~{year_range[1]}ë…„ ê¸°ì˜¨ ë³€í™” ì¶”ì´",
                           line_shape="spline", color_discrete_sequence=['#FF4B4B'])
        st.plotly_chart(fig_line, use_container_width=True)
        
    with col2:
        st.subheader("ðŸ“Š ìš”ì•½ ìˆ˜ì¹˜")
        avg_temp = filtered_weather['í‰ê· ê¸°ì˜¨(â„ƒ)'].mean()
        max_temp = filtered_weather['ìµœê³ ê¸°ì˜¨(â„ƒ)'].max()
        st.metric("í‰ê·  ê¸°ì˜¨", f"{avg_temp:.1f} Â°C")
        st.metric("ìµœê³  ê¸°ì˜¨", f"{max_temp:.1f} Â°C")
        
        # ê¸°ì˜¨ ë°ì´í„° AI ë¶„ì„ ë²„íŠ¼
        if st.button("AI ê¸°ìƒ ìºìŠ¤í„°ì—ê²Œ ë¬¼ì–´ë³´ê¸°"):
            if not user_api_key:
                st.warning("ðŸ‘ˆ ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë¨¼ì € ìž…ë ¥í•´ ì£¼ì„¸ìš”!")
            else:
                try:
                    genai.configure(api_key=user_api_key)
                    model = genai.GenerativeModel('gemini-1.5-flash')
                    
                    prompt = f"""
                    ë„ˆëŠ” ê¸°ìƒ ì „ë¬¸ê°€ì•¼. {year_range[0]}ë…„ë¶€í„° {year_range[1]}ë…„ê¹Œì§€ ì„œìš¸ì˜ í‰ê·  ê¸°ì˜¨ì€ {avg_temp:.1f}ë„ì˜€ê³ , 
                    ìµœê³  ê¸°ì˜¨ì€ {max_temp:.1f}ë„ì˜€ì–´. ì´ ë°ì´í„°ë¥¼ ë³´ê³  ìµœê·¼ ê¸°í›„ ë³€í™”ì˜ ì‹¬ê°ì„±ê³¼ 
                    ìš°ë¦¬ê°€ ì£¼ì˜í•´ì•¼ í•  ì ì„ ê³ ë“±í•™ìƒì˜ ëˆˆë†’ì´ì—ì„œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì¤˜.
                    """
                    
                    with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìžˆìŠµë‹ˆë‹¤..."):
                        response = model.generate_content(prompt)
                        st.chat_message("assistant").write(response.text)
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.info("ðŸ’¡ íŒ: API í‚¤ ë³µì‚¬ ì‹œ ê³µë°±ì´ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”!")

# --- [Tab 2: MBTI í†µê³„] ---
with tab2:
    st.header(f"{target_country} ì„±ê²© ë¶„í¬ ë¶„ì„")
    
    # ë°ì´í„° ë³€í™˜ (Melt)
    country_data = mbti_df[mbti_df['Country'] == target_country].drop(columns=['Country'])
    country_melted = country_data.melt(var_name='MBTI', value_name='Ratio')
    top_10_mbti = country_melted.sort_values(by='Ratio', ascending=False).head(10)
    
    col_bar, col_info = st.columns([6, 4])
    
    with col_bar:
        fig_bar = px.bar(top_10_mbti, x='MBTI', y='Ratio', 
                         title=f"{target_country} ì„±ê²© ìœ í˜• TOP 10",
                         color='Ratio', color_continuous_scale='Purples')
        st.plotly_chart(fig_bar, use_container_width=True)
        
    with col_info:
        st.subheader("ðŸ§ ë°ì´í„° í•´ì„ ë° AI ë¶„ì„")
        most_common = top_10_mbti.iloc[0]['MBTI']
        st.write(f"í˜„ìž¬ {target_country}ì—ì„œ ê°€ìž¥ ë†’ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” ìœ í˜•ì€ **{most_common}**ìž…ë‹ˆë‹¤.")
        
        # MBTI ë°ì´í„° AI ë¶„ì„ ë²„íŠ¼
        if st.button("Geminiì—ê²Œ ë¶„ì„ ê²°ê³¼ ë¬¼ì–´ë³´ê¸°"):
            if not user_api_key:
                st.warning("ðŸ‘ˆ ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë¨¼ì € ìž…ë ¥í•´ ì£¼ì„¸ìš”!")
            else:
                try:
                    # 1. API ì„¤ì •
                    genai.configure(api_key=user_api_key)
                    model = genai.GenerativeModel('gemini-1.5-flash')
                    
                    # 2. ë°ì´í„° í…ìŠ¤íŠ¸í™”
                    mbti_list_text = ", ".join([f"{row['MBTI']}({row['Ratio']*100:.1f}%)" for _, row in top_10_mbti.iterrows()])
                    
                    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    prompt = f"""
                    ë„ˆëŠ” ì„¸ê³„ ì„±ê²© ìœ í˜• ë¶„ì„ ì „ë¬¸ê°€ì•¼. {target_country}ì˜ ì„±ê²© ë¶„í¬ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„: {mbti_list_text}.
                    ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {target_country} ì‚¬ëžŒë“¤ì˜ ì „ë°˜ì ì¸ êµ­ë¯¼ì„±ê³¼ íŠ¹ì§•ì„ ë¶„ì„í•´ì¤˜.
                    ê·¸ë¦¬ê³  ì´ êµ­ê°€ë¡œ ì—¬í–‰ì„ ê°€ê±°ë‚˜ ì¹œêµ¬ë¥¼ ì‚¬ê·ˆ ë•Œ ì•Œì•„ë‘ë©´ ì¢‹ì€ íŒì„ 3ê°€ì§€ë¡œ ì •ë¦¬í•´ì„œ ì•Œë ¤ì¤˜.
                    ë‹µë³€ì€ ì¹œì ˆí•˜ê³  í¥ë¯¸ì§„ì§„í•œ ë§íˆ¬ë¡œ í•´ì¤˜!
                    """
                    
                    # 4. ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
                    with st.spinner("Geminiê°€ ë°ì´í„°ë¥¼ ì½ê³  ìƒê°í•˜ëŠ” ì¤‘..."):
                        response = model.generate_content(prompt)
                        st.markdown("---")
                        st.chat_message("assistant").write(response.text)
                        
                except Exception as e:
                    # [ìˆ˜ì • 2] ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¹œì ˆí•˜ê²Œ í‘œì‹œ
                    st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ëž˜ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.code(str(e))
                    st.warning("ðŸ’¡ í•´ê²°ë²•: API í‚¤ë¥¼ ë‹¤ì‹œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ì–´ ë³´ì„¸ìš” (ê³µë°± ì£¼ì˜!).")

# í•˜ë‹¨ í‘¸í„°
st.divider()
st.caption("Â© 2024 ë°”ì´ë¸Œ ì½”ë”©ìº í”„ - ë°ì´í„°ë¥¼ ì½ì–´ì£¼ëŠ” AI ëŒ€ì‹œë³´ë“œ âœ¨")
